modelv3.pth:

    model build:

        class CnnModel(nn.Module):
            def __init__(self, number_of_classes=25):
                super().__init__()
                self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2)
                self.conv2 = nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2)
                self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)
                self.conv4 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)
                self.conv5 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)
                self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
                self.fc1 = nn.Linear(128 * 8 * 8, 1024)
                self.fc2 = nn.Linear(1024, 512)
                self.fc3 = nn.Linear(512, number_of_classes)
                self.dropout = nn.Dropout(p=0.3)

            def forward(self, x):
                x = self.pool(F.relu(self.conv1(x)))
                x = self.pool(F.relu(self.conv2(x)))
                x = F.relu(self.conv3(x))
                x = F.relu(self.conv4(x))
                x = self.pool(F.relu(self.conv5(x)))
                x = x.view(-1, 128 * 8 * 8)
                x = self.dropout(F.relu(self.fc1(x)))
                x = self.dropout(F.relu(self.fc2(x)))
                x = self.fc3(x)
                return x

    learing configuration:

        train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=256, shuffle=True)
        val_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=256, shuffle=True)



        cnn_model = CnnModel()
        network_oper = NetworkOperations(cnn_model, check_point_name= 'model5_checkpoint.pth.tar')
        cnn_model = cnn_model.to(device)
        loss_fn = nn.CrossEntropyLoss()
        optimizer = optim.Adam(cnn_model.parameters(), lr=1e-5, weight_decay=0.003)

        network_oper.train_network(number_of_epoch = 20, train_loader = train_loader, val_loader = val_loader ,optimizer = optimizer, loss_fn = loss_fn, csv_save_path= 'data4.csv')

        checkpoint = torch.load('model5_checkpoint.pth.tar')

        cnn_model = CnnModel()
        cnn_model.load_state_dict(checkpoint['model'])
        cnn_model = cnn_model.to(device)
             

modelv6.pth: # no dropout on ff layers

    model build:

        class CnnModel(nn.Module):

            def __init__(self, number_of_classes = 25):
                super().__init__()
                self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2)
                self.conv2 = nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2)
                self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)
                self.conv4 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)
                self.conv5 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)
                self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
                self.fc1 = nn.Linear(128 * 8 * 8, 1024)
                self.fc2 = nn.Linear(1024, 512)
                self.fc3 = nn.Linear(512, number_of_classes)
                self.dropout = nn.Dropout(p = 0.3)

            def forward(self, x):
                x = self.pool(F.relu(self.conv1(x)))
                x = self.pool(F.relu(self.conv2(x)))
                x = F.relu(self.conv3(x))
                x = F.relu(self.conv4(x))
                x = self.pool(F.relu(self.conv5(x)))
                x = x.view(-1, 128 * 8 * 8)
                x = F.relu(self.fc1(x))
                x = F.relu(self.fc2(x))
                x = self.fc3(x)
                return x

    learing configuration:

        training_dataset = NumpyDrawingsDataset(training_data_path, transform= data_transforms)
        validation_dataset = NumpyDrawingsDataset(validation_data_path, transform= data_transforms)
        testing_dataset = NumpyDrawingsDataset(test_data_path, transform= data_transforms)

        train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=256, shuffle=True)
        val_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=256, shuffle=True)



        cnn_model = CnnModel()
        network_oper = NetworkOperations(cnn_model, check_point_name= 'model6_checkpoint.pth.tar') #if you waant new model change to model 7
        cnn_model = cnn_model.to(device)
        loss_fn = nn.CrossEntropyLoss()
        optimizer = optim.Adam(cnn_model.parameters(), lr=1e-5, weight_decay=0.003)

        network_oper.train_network(number_of_epoch = 30, train_loader = train_loader, val_loader = val_loader ,optimizer = optimizer, loss_fn = loss_fn, csv_save_path= 'data4.csv')

        checkpoint = torch.load('model6_checkpoint.pth.tar') #if you waant new model change to model 7

        cnn_model = CnnModel()
        cnn_model.load_state_dict(checkpoint['model'])
        cnn_model = cnn_model.to(device)

        torch.save(cnn_model, 'model_v6.pth') #if you waant new model change to model 7
                          

modelv7.pth: # sdg optim

    model build:

        class CnnModel(nn.Module):

            def __init__(self, number_of_classes = 25):
                super().__init__()
                self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2)
                self.conv2 = nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2)
                self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)
                self.conv4 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)
                self.conv5 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)
                self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)
                self.fc1 = nn.Linear(128 * 8 * 8, 1024)
                self.fc2 = nn.Linear(1024, 512)
                self.fc3 = nn.Linear(512, number_of_classes)
                self.dropout = nn.Dropout(p = 0.3)

            def forward(self, x):
                x = self.pool(F.relu(self.conv1(x)))
                x = self.pool(F.relu(self.conv2(x)))
                x = F.relu(self.conv3(x))
                x = F.relu(self.conv4(x))
                x = self.pool(F.relu(self.conv5(x)))
                x = x.view(-1, 128 * 8 * 8)
                x = F.relu(self.fc1(x))
                x = F.relu(self.fc2(x))
                x = self.fc3(x)
                return x

    learing configuration:

        train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=256, shuffle=True)
        val_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=256, shuffle=True)



        cnn_model = CnnModel()
        network_oper = NetworkOperations(cnn_model, check_point_name= 'model7_checkpoint.pth.tar') #if you waant new model change to model 8
        cnn_model = cnn_model.to(device)
        loss_fn = nn.CrossEntropyLoss()
        optimizer = optim.SGD(cnn_model.parameters(), lr=1e-2, weight_decay=0.0005)

        network_oper.train_network(number_of_epoch = 20, train_loader = train_loader, val_loader = val_loader ,optimizer = optimizer, loss_fn = loss_fn, csv_save_path= 'data7.csv') #if you waant new model change to data 8

        checkpoint = torch.load('model7_checkpoint.pth.tar') #if you waant new model change to model 8

        cnn_model = CnnModel()
        cnn_model.load_state_dict(checkpoint['model'])
        cnn_model = cnn_model.to(device)

        torch.save(cnn_model, 'model_v7.pth') #if you waant new model change to model 8